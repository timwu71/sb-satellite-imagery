{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_data.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEh5ojihBZ5_","executionInfo":{"status":"ok","timestamp":1651993000978,"user_tz":420,"elapsed":27564,"user":{"displayName":"Shayana Aarthy Venukanthan","userId":"03640355451445516907"}},"outputId":"42391861-ca00-4cea-f990-cbdcb5195ff8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Enter the foldername for the data set (added shortcut to 230/231N folder)\n","FOLDERNAME = 'Shareddrives/CS 230 231N/public_datasets'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\""],"metadata":{"id":"xQQ9TdrvBdKh","executionInfo":{"status":"ok","timestamp":1651993074733,"user_tz":420,"elapsed":184,"user":{"displayName":"Shayana Aarthy Venukanthan","userId":"03640355451445516907"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"FDGmVQOOAGa-","executionInfo":{"status":"ok","timestamp":1651993076319,"user_tz":420,"elapsed":153,"user":{"displayName":"Shayana Aarthy Venukanthan","userId":"03640355451445516907"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["import sys\n","dataset_path = '/content/drive/My Drive/{}'.format(FOLDERNAME)\n","# sys.path.append(dataset_path)"],"metadata":{"id":"ALWMS73sCxkr","executionInfo":{"status":"ok","timestamp":1651993080277,"user_tz":420,"elapsed":188,"user":{"displayName":"Shayana Aarthy Venukanthan","userId":"03640355451445516907"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from concurrent.futures import ThreadPoolExecutor\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from tqdm.auto import tqdm"],"metadata":{"id":"qugBs-GCAUON","executionInfo":{"status":"ok","timestamp":1651993085219,"user_tz":420,"elapsed":817,"user":{"displayName":"Shayana Aarthy Venukanthan","userId":"03640355451445516907"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# dataset_root_dir = '/content/drive/Shareddrives/CS 230 231N/sustainbench-main/sustainbench-main/dataset_preprocessing/dhs_lsms'"],"metadata":{"id":"wtwh_XP2AUm9","executionInfo":{"status":"ok","timestamp":1651993098302,"user_tz":420,"elapsed":214,"user":{"displayName":"Shayana Aarthy Venukanthan","userId":"03640355451445516907"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# TODO: copy dhs_final_labels.csv to VM, change os path below accordingly\n","df = pd.read_csv(os.path.join(dataset_root_dir, 'output_labels/dhs_final_labels.csv'))\n","df['survey'] = df['DHSID_EA'].str[:10]\n","df['cc'] = df['DHSID_EA'].str[:2]\n","\n","# TODO: run modified version of get_public_datasets.py, change data_dir below to match VM path\n","data_dir = '/content/drive/Shareddrives/CS 230 231N/dhs_datasets/'\n","df['path'] = data_dir + df['survey'] + '/' + df['DHSID_EA'] + '.npz'\n","# df['path'] = dataset_root_dir + '/dhs_npzs/' + df['survey'] + '/' + df['DHSID_EA'] + '.npz'\n","\n","path_years = df[['DHSID_EA', 'path', 'year']].apply(tuple, axis=1)\n","df.set_index('DHSID_EA', verify_integrity=True, inplace=True, drop=False) #had to add drop=False to keep column from disappearing  -- R\n","print(df['path'].iloc[0])\n","df.info()\n","display(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"k_iVBcDmAVO6","executionInfo":{"status":"ok","timestamp":1651993108280,"user_tz":420,"elapsed":4604,"user":{"displayName":"Shayana Aarthy Venukanthan","userId":"03640355451445516907"}},"outputId":"386d1fb1-b9ee-4142-9742-14d70cded87b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/CS 230 231N/dhs_datasets/AL-2008-5#/AL-2008-5#-00000001.npz\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 117644 entries, AL-2008-5#-00000001 to ZW-2015-7#-00000400\n","Data columns (total 24 columns):\n"," #   Column            Non-Null Count   Dtype  \n","---  ------            --------------   -----  \n"," 0   DHSID_EA          117644 non-null  object \n"," 1   cname             117644 non-null  object \n"," 2   year              117644 non-null  int64  \n"," 3   lat               117644 non-null  float64\n"," 4   lon               117644 non-null  float64\n"," 5   n_asset           86936 non-null   float64\n"," 6   asset_index       86936 non-null   float64\n"," 7   n_water           87938 non-null   float64\n"," 8   water_index       87938 non-null   float64\n"," 9   n_sanitation      89271 non-null   float64\n"," 10  sanitation_index  89271 non-null   float64\n"," 11  under5_mort       105582 non-null  float64\n"," 12  n_under5_mort     105582 non-null  float64\n"," 13  women_edu         117062 non-null  float64\n"," 14  women_bmi         94866 non-null   float64\n"," 15  n_women_edu       117062 non-null  float64\n"," 16  n_women_bmi       94866 non-null   float64\n"," 17  cluster_id        117644 non-null  int64  \n"," 18  adm1fips          45916 non-null   object \n"," 19  adm1dhs           117644 non-null  int64  \n"," 20  urban             117644 non-null  object \n"," 21  survey            117644 non-null  object \n"," 22  cc                117644 non-null  object \n"," 23  path              117644 non-null  object \n","dtypes: float64(14), int64(3), object(7)\n","memory usage: 22.4+ MB\n"]},{"output_type":"display_data","data":{"text/plain":["                                DHSID_EA cname  year        lat        lon  \\\n","DHSID_EA                                                                     \n","AL-2008-5#-00000001  AL-2008-5#-00000001    AL  2008  40.822652  19.838321   \n","AL-2008-5#-00000002  AL-2008-5#-00000002    AL  2008  40.696846  20.007555   \n","AL-2008-5#-00000003  AL-2008-5#-00000003    AL  2008  40.750037  19.974262   \n","AL-2008-5#-00000004  AL-2008-5#-00000004    AL  2008  40.798931  19.863338   \n","AL-2008-5#-00000005  AL-2008-5#-00000005    AL  2008  40.746123  19.843885   \n","\n","                     n_asset  asset_index  n_water  water_index  n_sanitation  \\\n","DHSID_EA                                                                        \n","AL-2008-5#-00000001     18.0     2.430596     18.0     3.444444          18.0   \n","AL-2008-5#-00000002     20.0     2.867678     20.0     4.700000          20.0   \n","AL-2008-5#-00000003     18.0     2.909049     18.0     4.500000          18.0   \n","AL-2008-5#-00000004     19.0     2.881122     19.0     4.947368          19.0   \n","AL-2008-5#-00000005     19.0     2.546830     19.0     4.684211          19.0   \n","\n","                     ...  women_bmi  n_women_edu  n_women_bmi  cluster_id  \\\n","DHSID_EA             ...                                                    \n","AL-2008-5#-00000001  ...  24.365000         18.0         18.0           1   \n","AL-2008-5#-00000002  ...  23.104000         20.0         20.0           2   \n","AL-2008-5#-00000003  ...  22.387778         18.0         18.0           3   \n","AL-2008-5#-00000004  ...  27.084500         21.0         20.0           4   \n","AL-2008-5#-00000005  ...  24.523125         16.0         16.0           5   \n","\n","                     adm1fips  adm1dhs  urban      survey  cc  \\\n","DHSID_EA                                                        \n","AL-2008-5#-00000001       NaN     9999      R  AL-2008-5#  AL   \n","AL-2008-5#-00000002       NaN     9999      R  AL-2008-5#  AL   \n","AL-2008-5#-00000003       NaN     9999      R  AL-2008-5#  AL   \n","AL-2008-5#-00000004       NaN     9999      R  AL-2008-5#  AL   \n","AL-2008-5#-00000005       NaN     9999      R  AL-2008-5#  AL   \n","\n","                                                                  path  \n","DHSID_EA                                                                \n","AL-2008-5#-00000001  /content/drive/Shareddrives/CS 230 231N/dhs_da...  \n","AL-2008-5#-00000002  /content/drive/Shareddrives/CS 230 231N/dhs_da...  \n","AL-2008-5#-00000003  /content/drive/Shareddrives/CS 230 231N/dhs_da...  \n","AL-2008-5#-00000004  /content/drive/Shareddrives/CS 230 231N/dhs_da...  \n","AL-2008-5#-00000005  /content/drive/Shareddrives/CS 230 231N/dhs_da...  \n","\n","[5 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-b05d367d-2e12-41a9-95a4-f39ffbadb979\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DHSID_EA</th>\n","      <th>cname</th>\n","      <th>year</th>\n","      <th>lat</th>\n","      <th>lon</th>\n","      <th>n_asset</th>\n","      <th>asset_index</th>\n","      <th>n_water</th>\n","      <th>water_index</th>\n","      <th>n_sanitation</th>\n","      <th>...</th>\n","      <th>women_bmi</th>\n","      <th>n_women_edu</th>\n","      <th>n_women_bmi</th>\n","      <th>cluster_id</th>\n","      <th>adm1fips</th>\n","      <th>adm1dhs</th>\n","      <th>urban</th>\n","      <th>survey</th>\n","      <th>cc</th>\n","      <th>path</th>\n","    </tr>\n","    <tr>\n","      <th>DHSID_EA</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>AL-2008-5#-00000001</th>\n","      <td>AL-2008-5#-00000001</td>\n","      <td>AL</td>\n","      <td>2008</td>\n","      <td>40.822652</td>\n","      <td>19.838321</td>\n","      <td>18.0</td>\n","      <td>2.430596</td>\n","      <td>18.0</td>\n","      <td>3.444444</td>\n","      <td>18.0</td>\n","      <td>...</td>\n","      <td>24.365000</td>\n","      <td>18.0</td>\n","      <td>18.0</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>9999</td>\n","      <td>R</td>\n","      <td>AL-2008-5#</td>\n","      <td>AL</td>\n","      <td>/content/drive/Shareddrives/CS 230 231N/dhs_da...</td>\n","    </tr>\n","    <tr>\n","      <th>AL-2008-5#-00000002</th>\n","      <td>AL-2008-5#-00000002</td>\n","      <td>AL</td>\n","      <td>2008</td>\n","      <td>40.696846</td>\n","      <td>20.007555</td>\n","      <td>20.0</td>\n","      <td>2.867678</td>\n","      <td>20.0</td>\n","      <td>4.700000</td>\n","      <td>20.0</td>\n","      <td>...</td>\n","      <td>23.104000</td>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>9999</td>\n","      <td>R</td>\n","      <td>AL-2008-5#</td>\n","      <td>AL</td>\n","      <td>/content/drive/Shareddrives/CS 230 231N/dhs_da...</td>\n","    </tr>\n","    <tr>\n","      <th>AL-2008-5#-00000003</th>\n","      <td>AL-2008-5#-00000003</td>\n","      <td>AL</td>\n","      <td>2008</td>\n","      <td>40.750037</td>\n","      <td>19.974262</td>\n","      <td>18.0</td>\n","      <td>2.909049</td>\n","      <td>18.0</td>\n","      <td>4.500000</td>\n","      <td>18.0</td>\n","      <td>...</td>\n","      <td>22.387778</td>\n","      <td>18.0</td>\n","      <td>18.0</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>9999</td>\n","      <td>R</td>\n","      <td>AL-2008-5#</td>\n","      <td>AL</td>\n","      <td>/content/drive/Shareddrives/CS 230 231N/dhs_da...</td>\n","    </tr>\n","    <tr>\n","      <th>AL-2008-5#-00000004</th>\n","      <td>AL-2008-5#-00000004</td>\n","      <td>AL</td>\n","      <td>2008</td>\n","      <td>40.798931</td>\n","      <td>19.863338</td>\n","      <td>19.0</td>\n","      <td>2.881122</td>\n","      <td>19.0</td>\n","      <td>4.947368</td>\n","      <td>19.0</td>\n","      <td>...</td>\n","      <td>27.084500</td>\n","      <td>21.0</td>\n","      <td>20.0</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>9999</td>\n","      <td>R</td>\n","      <td>AL-2008-5#</td>\n","      <td>AL</td>\n","      <td>/content/drive/Shareddrives/CS 230 231N/dhs_da...</td>\n","    </tr>\n","    <tr>\n","      <th>AL-2008-5#-00000005</th>\n","      <td>AL-2008-5#-00000005</td>\n","      <td>AL</td>\n","      <td>2008</td>\n","      <td>40.746123</td>\n","      <td>19.843885</td>\n","      <td>19.0</td>\n","      <td>2.546830</td>\n","      <td>19.0</td>\n","      <td>4.684211</td>\n","      <td>19.0</td>\n","      <td>...</td>\n","      <td>24.523125</td>\n","      <td>16.0</td>\n","      <td>16.0</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>9999</td>\n","      <td>R</td>\n","      <td>AL-2008-5#</td>\n","      <td>AL</td>\n","      <td>/content/drive/Shareddrives/CS 230 231N/dhs_da...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 24 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b05d367d-2e12-41a9-95a4-f39ffbadb979')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b05d367d-2e12-41a9-95a4-f39ffbadb979 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b05d367d-2e12-41a9-95a4-f39ffbadb979');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["Assuming we are connected to a VM that has all the data and has already run a modified version of get_public_datasets.py that unzipped files from \"data\" folder and placed them in the \"dhs_datasets\" folder:"],"metadata":{"id":"wRwaqreYeYwn"}},{"cell_type":"code","source":["# Function: paths_to_X\n","# build input matrix X by iterating through each path in paths, load image, insert in X\n","def paths_to_X(paths):  # -> (N, C, H, W) model input X\n","  '''\n","    Args\n","    - paths: array (N, 1)\n","      - path: str, path to npz file containing single entry 'x'\n","        representing a (C, H, W) image\n","\n","    Returns: X, input matrix (N, C, H, W)\n","    '''\n","  N = len(paths)  # should be 117644\n","  C, H, W = 8, 255, 255\n","  X = np.zeros((N, C, H, W))\n","  for n in range(N):\n","    npz_path = paths[n]\n","    img = np.load(npz_path)['x']  # shape (C, H, W)\n","    X[n, :, :, :] = img\n","  return X"],"metadata":{"id":"oxJQ7Uk8eXEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label_cols = ['asset_index', 'under5_mort', 'women_bmi', 'women_edu', 'water_index', 'sanitation_index']\n","# label_cols = ['n_under5_mort']\n","label = \"n_under5_mort\""],"metadata":{"id":"5J-qvpNeAcaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SPLITS = {\n","    'train': [\n","        'AL', 'BD', 'CD', 'CM', 'GH', 'GU', 'HN', 'IA', 'ID', 'JO', 'KE', 'KM',\n","        'LB', 'LS', 'MA', 'MB', 'MD', 'MM', 'MW', 'MZ', 'NG', 'NI', 'PE', 'PH',\n","        'SN', 'TG', 'TJ', 'UG', 'ZM', 'ZW'],\n","    'val': [\n","        'BF', 'BJ', 'BO', 'CO', 'DR', 'GA', 'GN', 'GY', 'HT', 'NM', 'SL', 'TD',\n","        'TZ'],\n","    'test': [\n","        'AM', 'AO', 'BU', 'CI', 'EG', 'ET', 'KH', 'KY', 'ML', 'NP', 'PK', 'RW',\n","        'SZ']\n","}\n","SPLITS['trainval'] = SPLITS['train'] + SPLITS['val']"],"metadata":{"id":"2NJqCig9AloV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_train_and_test(label, trainsplit='train', testsplit='test'):\n","    train_dhsids = df.index[df['cc'].isin(SPLITS[trainsplit]) & df[label].notna()]\n","    test_dhsids = df.index[df['cc'].isin(SPLITS[testsplit]) & df[label].notna()]\n","\n","    train_X_paths = df.loc[train_dhsids, 'path'].values.reshape(-1, 1)\n","    train_X = paths_to_X(train_X_paths)\n","    train_Y = df.loc[train_dhsids, label].values\n","    test_X_paths = df.loc[test_dhsids, 'path'].values.reshape(-1, 1)\n","    test_X = paths_to_X(test_X_paths)\n","    test_Y = df.loc[test_dhsids, label].values\n","\n","    # knn.fit(train_X, train_Y)\n","    # preds = knn.predict(test_X)\n","    return train_X, train_Y, test_X, test_Y"],"metadata":{"id":"3RKf2DuNl9NO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X, train_Y, val_X, val_Y = get_train_and_test(label, 'train', 'val') \n","trainval_X, trainval_Y, test_X, test_Y = get_train_and_test(label, 'trainval', 'test')\n","print(\"train_X: \", train_X.shape)\n","print(\"train_Y: \", train_Y.shape)\n","print(\"trainval_X: \", trainval_X.shape)\n","print(\"trainval_Y: \", trainval_Y.shape)\n","print(\"val_X: \", val_X.shape)\n","print(\"val_Y: \", val_Y.shape)\n","print(\"test_X: \", test_X.shape)\n","print(\"test_Y: \", test_Y.shape)"],"metadata":{"id":"vIGezxheuXyU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# IGNORE AFTER THIS - NOT DONE\n"],"metadata":{"id":"joQLB8fLukM0"}},{"cell_type":"code","source":["# From assignment2 PyTorch.ipynb\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np\n","\n","USE_GPU = True\n","dtype = torch.float32 # We will be using float throughout this tutorial.\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss.\n","print_every = 100\n","print('using device:', device)"],"metadata":{"id":"RQ26hn7SApCU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# From assignment2 PyTorch.ipynb\n","\n","def check_accuracy_part34(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')   \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"],"metadata":{"id":"HY9KYIShsyo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# From assignment2 PyTorch.ipynb\n","\n","def train_part34(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model using the PyTorch Module API.\n","    \n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","    \n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()\n"],"metadata":{"id":"tglOer9aLgVG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["solver = Solver(model, \n","                data,\n","                update_rule=update_rule,\n","                optim_config=optim_config,\n","                #lr_decay=lr_decay,\n","                num_epochs=num_epochs, \n","                batch_size=batch_size,\n","                print_every=print_every)\n","tr = solver.train()"],"metadata":{"id":"z69nOU-fMnNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize train + val accuracy\n","plt.subplot(2, 1, 1)\n","plt.title('Training loss')\n","plt.plot(solver.loss_history, 'o')\n","plt.xlabel('Iteration')\n","\n","plt.subplot(2, 1, 2)\n","plt.title('Accuracy')\n","plt.plot(solver.train_acc_history, '-o', label='train')\n","plt.plot(solver.val_acc_history, '-o', label='val')\n","plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n","plt.xlabel('Epoch')\n","plt.legend(loc='lower right')\n","plt.gcf().set_size_inches(15, 12)\n","plt.show()"],"metadata":{"id":"T5x0lijUK80r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = None\n","best_val = 0\n","\n","# hyperparams\n","\n","for None:\n","      model = None #TODO: model\n","      solver = Solver(model, \n","                data,\n","                update_rule=update_rule,\n","                optim_config=optim_config,\n","                #lr_decay=lr_decay,\n","                num_epochs=num_epochs, \n","                batch_size=batch_size,\n","                print_every=print_every,\n","                verbose=False)\n","      tr = solver.train()\n","      \n","      # TODO: re-format to appropriate data format\n","      train_acc = solver.check_accuracy(data['X_train'], data['y_train'])\n","      val_acc = solver.check_accuracy(data['X_val'], data['y_val'])\n","      \n","      # TODO: once hyperparams picked\n","      print('results')\n","      if val_acc > best_val:\n","        best_model = model\n","        best_val = val_acc\n"],"metadata":{"id":"aNBmYMmUOOPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: determine how to give predicted regression\n","y_val_pred = best_model.loss(data['X_test'])\n","y_test_pred = best_model.loss(data['X_val'])\n","\n","\n","#TODO: evaluation metric\n","\n","#TODO: print results"],"metadata":{"id":"-IyE8WFxRILk"},"execution_count":null,"outputs":[]}]}