{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_loader_attempt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DataSet and DataLoaders for SustainBench Data\n",
        "\n",
        "Links I referenced:\n",
        "\n",
        "*   https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "*   https://pytorch.org/docs/stable/data.html\n",
        "*   https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
        "*   https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
        "\n",
        "\n",
        "**PLEASE NOTE:** You will need to change the datasets (train_dataset, val_dataset) to use the corresponding splits ('train', 'val', etc.) below. Currently all datasets use the 'partial' version of the splits.\n",
        "\n",
        "**NOTE:** The \"check_accuracy\" function only uses accuracy, not the r^2 score.\n",
        "\n",
        "Right now, it is taking a LONG"
      ],
      "metadata": {
        "id": "TdHWO0GuwDoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEh5ojihBZ5_",
        "outputId": "586b0f48-4041-46bd-903f-e9633dbe5299"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter the foldername for the data set (added shortcut to 230/231N folder)\n",
        "FOLDERNAME = 'Shareddrives/CS 230 231N/public_datasets'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\""
      ],
      "metadata": {
        "id": "xQQ9TdrvBdKh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FDGmVQOOAGa-"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "dataset_path = '/content/drive/My Drive/{}'.format(FOLDERNAME)\n",
        "# sys.path.append(dataset_path)"
      ],
      "metadata": {
        "id": "ALWMS73sCxkr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "qugBs-GCAUON"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root_dir = '/content/drive/Shareddrives/CS 230 231N/sustainbench-main/sustainbench-main/dataset_preprocessing/dhs_lsms'"
      ],
      "metadata": {
        "id": "wtwh_XP2AUm9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = ['asset_index', 'under5_mort', 'women_bmi', 'women_edu', 'water_index', 'sanitation_index']"
      ],
      "metadata": {
        "id": "5J-qvpNeAcaB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import torch.nn.functional as F  # useful stateless functions\n",
        "import scipy"
      ],
      "metadata": {
        "id": "qagGmlMrTA2K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_GPU = True\n",
        "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss.\n",
        "print_every = 100\n",
        "print('using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEjFz0dvlZXW",
        "outputId": "8bff0d58-2a38-4df3-f993-3de3ec9eed58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"n_under5_mort\"\n",
        "\n",
        "SPLITS = {\n",
        "    'train': [\n",
        "        'AL', 'BD', 'CD', 'CM', 'GH', 'GU', 'HN', 'IA', 'ID', 'JO', 'KE', 'KM',\n",
        "        'LB', 'LS', 'MA', 'MB', 'MD', 'MM', 'MW', 'MZ', 'NG', 'NI', 'PE', 'PH',\n",
        "        'SN', 'TG', 'TJ', 'UG', 'ZM', 'ZW'],\n",
        "    'val': [\n",
        "        'BF', 'BJ', 'BO', 'CO', 'DR', 'GA', 'GN', 'GY', 'HT', 'NM', 'SL', 'TD',\n",
        "        'TZ'],\n",
        "    'test': [\n",
        "        'AM', 'AO', 'BU', 'CI', 'EG', 'ET', 'KH', 'KY', 'ML', 'NP', 'PK', 'RW',\n",
        "        'SZ']\n",
        "}\n",
        "SPLITS['trainval'] = SPLITS['train'] + SPLITS['val']\n",
        "\n",
        "#partial splits\n",
        "\n",
        "SPLITS['train_partial'] = SPLITS['train'][:2]\n",
        "SPLITS['val_partial'] = SPLITS['val'][:2]\n",
        "SPLITS['test_partial'] = SPLITS['test'][:2]\n",
        "SPLITS['trainval_partial'] = SPLITS['train_partial'] + SPLITS['val_partial']"
      ],
      "metadata": {
        "id": "jxHx2Pr3Zeg5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SustainBenchDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, file_ext, split, category, bands=None, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.split = split\n",
        "        self.bands = bands\n",
        "        self.category = category\n",
        "        self.img_labels['survey'] = self.img_labels['DHSID_EA'].str[:10]\n",
        "        self.img_labels['cc'] = self.img_labels['DHSID_EA'].str[:2]\n",
        "        # Set up dataframe to have accurate path names\n",
        "        self.img_labels['survey'] = self.img_labels['DHSID_EA'].str[:10]\n",
        "        self.img_labels['cc'] = self.img_labels['DHSID_EA'].str[:2]\n",
        "        self.img_labels['path'] = img_dir + self.img_labels['survey'] + '/' + self.img_labels['DHSID_EA'] + file_ext\n",
        "        # Only include necessary countries' data with non NaN values\n",
        "        self.df_split = self.img_labels[self.img_labels['cc'].isin(SPLITS[split]) & self.img_labels[category].notna()].copy()\n",
        "        path_years = self.df_split[['DHSID_EA', 'path', 'year']].apply(tuple, axis=1)\n",
        "        self.df_split.set_index('DHSID_EA', verify_integrity=True, inplace=True, drop=False) #drop=False to keep column from disappearing\n",
        "        print()\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_split)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        df_row = self.df_split.iloc[idx]\n",
        "        image = np.load(df_row['path'])['x']  # with all 8 channels \n",
        "\n",
        "        # Reduce to 3 bands/channels at a time if needed\n",
        "        if self.bands is not None:\n",
        "          image = np.load(df_row['path'])['x'][self.bands, :, :]\n",
        "        \n",
        "        label = df_row[self.category]\n",
        "\n",
        "        # Apply transforms if needed\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Yegk3S15S1HE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SustainBenchDataset(\n",
        "    annotations_file=os.path.join(dataset_root_dir, 'output_labels/dhs_final_labels.csv'),\n",
        "    img_dir='/content/drive/Shareddrives/CS 230 231N/dhs_datasets/',\n",
        "    category = 'n_under5_mort',\n",
        "    file_ext = '.npz',\n",
        "    split = 'train_partial',\n",
        "    # bands = [0, 1, 2]\n",
        "    #transform=ToTensor()\n",
        ")\n",
        "\n",
        "val_dataset = SustainBenchDataset(\n",
        "    annotations_file=os.path.join(dataset_root_dir, 'output_labels/dhs_final_labels.csv'),\n",
        "    img_dir='/content/drive/Shareddrives/CS 230 231N/dhs_datasets/',\n",
        "    category = 'n_under5_mort',\n",
        "    file_ext = '.npz',\n",
        "    split = 'val_partial',  #TODO: CHANGE THIS TO VAL\n",
        "    # bands = [0, 1, 2]\n",
        "    #transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_dataset = SustainBenchDataset(\n",
        "    annotations_file=os.path.join(dataset_root_dir, 'output_labels/dhs_final_labels.csv'),\n",
        "    img_dir='/content/drive/Shareddrives/CS 230 231N/dhs_datasets/',\n",
        "    category = 'n_under5_mort',\n",
        "    file_ext = '.npz',\n",
        "    split = 'test_partial',  #TODO: CHANGE THIS TO TEST\n",
        "    # bands = [0, 1, 2]\n",
        "    #transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVBzZTUUTkdV",
        "outputId": "d869542f-ef7c-4dda-beb0-9e399d536195"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
        "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
        "# iterates through the Dataset and forms minibatches. We divide the SustainBench\n",
        "# training set into train and val sets using the splits above\n",
        "\n",
        "#TODO: use num_workers=<insert number> to help speed up the process\n",
        "loader_train = DataLoader(train_dataset, batch_size=64, num_workers=2)\n",
        "\n",
        "loader_val = DataLoader(val_dataset, batch_size=64, num_workers=2)\n",
        "\n",
        "loader_test = DataLoader(test_dataset, batch_size=64, num_workers=2)"
      ],
      "metadata": {
        "id": "P29gmzzrktc2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy_part34(loader, model, val_or_test=\"val\"):\n",
        "    if val_or_test == \"val\":\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "\n",
        "    all_preds = []\n",
        "    Y = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x).cpu().numpy()\n",
        "            # _, preds = scores.max(1)\n",
        "            # num_correct += (preds == y).sum()\n",
        "            # num_samples += preds.size(0)\n",
        "            #print(scores.shape)\n",
        "            preds = np.argmax(scores, axis=1)\n",
        "            num_correct += (preds == y.cpu().numpy()).sum()\n",
        "            num_samples += preds.shape[0]\n",
        "\n",
        "        # TODO: calculate r^2 scoure\n",
        "        r2 = 0\n",
        "        # # for r^2\n",
        "        # all_preds.append(preds)\n",
        "        # all_preds = np.concatenate(all_preds, axis=0)\n",
        "        # print('preds:', all_preds[:10], 'actual:', Y.cpu().numpy()[:10])\n",
        "        # r2, _ = scipy.stats.pearsonr(all_preds, Y.cpu().numpy()[:all_preds.shape[0]])\n",
        "\n",
        "        # r2 = r2 ** 2\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        return acc, r2"
      ],
      "metadata": {
        "id": "I4Y79jP3lXxW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_part34(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part34(loader_val, model)\n",
        "                print()"
      ],
      "metadata": {
        "id": "5j0wKyRtmc6Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(x):\n",
        "    N = x.shape[0] # read in N, C, H, W\n",
        "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
        "\n",
        "# We need to wrap `flatten` function in a module in order to stack it\n",
        "# in nn.Sequential\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return flatten(x)"
      ],
      "metadata": {
        "id": "HA0Y4JYtnA82"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val = 0\n",
        "best_lr = None\n",
        "\n",
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "channel_0 = 8\n",
        "channel_1 = 64\n",
        "channel_2 = 64\n",
        "channel_3 = 32\n",
        "hidden_layer_size_1 = 128\n",
        "hidden_layer_size_2 = 32\n",
        "learning_rates = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
        "drop_probs = [0, 0.2, 0.5, 0.8]"
      ],
      "metadata": {
        "id": "YkhlBQagnFBq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for drop_prob in drop_probs:\n",
        "    for learning_rate in learning_rates:\n",
        "        model = nn.Sequential(\n",
        "        nn.Conv2d(channel_0, channel_1, (3, 3), padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d((2, 2), stride=2),  # changes H, W from 32 to 16\n",
        "        nn.Dropout2d(drop_prob),\n",
        "        nn.Conv2d(channel_1, channel_2, (3, 3), padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d((2, 2), stride=2),  # changes H, W from 16 to 8\n",
        "        nn.Dropout2d(drop_prob),\n",
        "        nn.Conv2d(channel_2, channel_3, (3, 3), padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d((2, 2), stride=2),  # changes H, W from 8 to 4\n",
        "        nn.BatchNorm2d(num_features = channel_3),\n",
        "        Flatten(),\n",
        "        nn.Linear(30752, hidden_layer_size_1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(drop_prob),\n",
        "        nn.Linear(hidden_layer_size_1, hidden_layer_size_2),    \n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer_size_2, 167),\n",
        "        )\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "\n",
        "        print('LEARNING RATE:', learning_rate, 'DROP PROB:', drop_prob)\n",
        "        train_part34(model, optimizer, epochs=5)\n",
        "        val_acc, r2 = check_accuracy_part34(loader_val, model, \"val\")\n",
        "\n",
        "        if r2 > best_val:\n",
        "            best_model = model\n",
        "            best_lr = learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_48nbQfnIuV",
        "outputId": "44f8b041-edfa-4160-aa25-8f22f3f1997a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LEARNING RATE: 0.001 DROP PROB: 0\n",
            "Iteration 0, loss = 5.1311\n",
            "Checking accuracy on validation set\n",
            "Got 3 / 3183 correct (0.09)\n",
            "\n",
            "Iteration 0, loss = 4.3544\n",
            "Checking accuracy on validation set\n",
            "Got 91 / 3183 correct (2.86)\n",
            "\n",
            "Iteration 0, loss = 3.8911\n",
            "Checking accuracy on validation set\n",
            "Got 91 / 3183 correct (2.86)\n",
            "\n",
            "Iteration 0, loss = 3.8886\n",
            "Checking accuracy on validation set\n",
            "Got 91 / 3183 correct (2.86)\n",
            "\n",
            "Iteration 0, loss = 3.9063\n",
            "Checking accuracy on validation set\n",
            "Got 92 / 3183 correct (2.89)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 92 / 3183 correct (2.89)\n",
            "LEARNING RATE: 0.0001 DROP PROB: 0\n",
            "Iteration 0, loss = 5.1620\n",
            "Checking accuracy on validation set\n",
            "Got 75 / 3183 correct (2.36)\n",
            "\n",
            "Iteration 0, loss = 5.0621\n",
            "Checking accuracy on validation set\n",
            "Got 122 / 3183 correct (3.83)\n",
            "\n",
            "Iteration 0, loss = 5.0349\n",
            "Checking accuracy on validation set\n",
            "Got 122 / 3183 correct (3.83)\n",
            "\n",
            "Iteration 0, loss = 4.9424\n",
            "Checking accuracy on validation set\n",
            "Got 122 / 3183 correct (3.83)\n",
            "\n",
            "Iteration 0, loss = 4.8579\n",
            "Checking accuracy on validation set\n",
            "Got 122 / 3183 correct (3.83)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 122 / 3183 correct (3.83)\n",
            "LEARNING RATE: 1e-05 DROP PROB: 0\n",
            "Iteration 0, loss = 5.1016\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.0613\n",
            "Checking accuracy on validation set\n",
            "Got 9 / 3183 correct (0.28)\n",
            "\n",
            "Iteration 0, loss = 5.0445\n",
            "Checking accuracy on validation set\n",
            "Got 15 / 3183 correct (0.47)\n",
            "\n",
            "Iteration 0, loss = 5.0319\n",
            "Checking accuracy on validation set\n",
            "Got 17 / 3183 correct (0.53)\n",
            "\n",
            "Iteration 0, loss = 5.0207\n",
            "Checking accuracy on validation set\n",
            "Got 18 / 3183 correct (0.57)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 18 / 3183 correct (0.57)\n",
            "LEARNING RATE: 1e-06 DROP PROB: 0\n",
            "Iteration 0, loss = 5.0691\n",
            "Checking accuracy on validation set\n",
            "Got 2 / 3183 correct (0.06)\n",
            "\n",
            "Iteration 0, loss = 5.0597\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.0557\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.0517\n",
            "Checking accuracy on validation set\n",
            "Got 1 / 3183 correct (0.03)\n",
            "\n",
            "Iteration 0, loss = 5.0540\n",
            "Checking accuracy on validation set\n",
            "Got 1 / 3183 correct (0.03)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 1 / 3183 correct (0.03)\n",
            "LEARNING RATE: 1e-07 DROP PROB: 0\n",
            "Iteration 0, loss = 5.1708\n",
            "Checking accuracy on validation set\n",
            "Got 28 / 3183 correct (0.88)\n",
            "\n",
            "Iteration 0, loss = 5.1687\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.1662\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.1637\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.1612\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "LEARNING RATE: 0.001 DROP PROB: 0.2\n",
            "Iteration 0, loss = 5.1749\n",
            "Checking accuracy on validation set\n",
            "Got 1 / 3183 correct (0.03)\n",
            "\n",
            "Iteration 0, loss = 4.7745\n",
            "Checking accuracy on validation set\n",
            "Got 80 / 3183 correct (2.51)\n",
            "\n",
            "Iteration 0, loss = 3.8700\n",
            "Checking accuracy on validation set\n",
            "Got 123 / 3183 correct (3.86)\n",
            "\n",
            "Iteration 0, loss = 4.1037\n",
            "Checking accuracy on validation set\n",
            "Got 93 / 3183 correct (2.92)\n",
            "\n",
            "Iteration 0, loss = 4.0131\n",
            "Checking accuracy on validation set\n",
            "Got 93 / 3183 correct (2.92)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 93 / 3183 correct (2.92)\n",
            "LEARNING RATE: 0.0001 DROP PROB: 0.2\n",
            "Iteration 0, loss = 5.1625\n",
            "Checking accuracy on validation set\n",
            "Got 2 / 3183 correct (0.06)\n",
            "\n",
            "Iteration 0, loss = 5.1143\n",
            "Checking accuracy on validation set\n",
            "Got 24 / 3183 correct (0.75)\n",
            "\n",
            "Iteration 0, loss = 5.1034\n",
            "Checking accuracy on validation set\n",
            "Got 23 / 3183 correct (0.72)\n",
            "\n",
            "Iteration 0, loss = 5.1306\n",
            "Checking accuracy on validation set\n",
            "Got 39 / 3183 correct (1.23)\n",
            "\n",
            "Iteration 0, loss = 5.1113\n",
            "Checking accuracy on validation set\n",
            "Got 3 / 3183 correct (0.09)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 3 / 3183 correct (0.09)\n",
            "LEARNING RATE: 1e-05 DROP PROB: 0.2\n",
            "Iteration 0, loss = 5.1063\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.1144\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.1074\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.1014\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.0996\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "LEARNING RATE: 1e-06 DROP PROB: 0.2\n",
            "Iteration 0, loss = 5.0903\n",
            "Checking accuracy on validation set\n",
            "Got 28 / 3183 correct (0.88)\n",
            "\n",
            "Iteration 0, loss = 5.0853\n",
            "Checking accuracy on validation set\n",
            "Got 101 / 3183 correct (3.17)\n",
            "\n",
            "Iteration 0, loss = 5.0963\n",
            "Checking accuracy on validation set\n",
            "Got 101 / 3183 correct (3.17)\n",
            "\n",
            "Iteration 0, loss = 5.0930\n",
            "Checking accuracy on validation set\n",
            "Got 101 / 3183 correct (3.17)\n",
            "\n",
            "Iteration 0, loss = 5.0746\n",
            "Checking accuracy on validation set\n",
            "Got 101 / 3183 correct (3.17)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 101 / 3183 correct (3.17)\n",
            "LEARNING RATE: 1e-07 DROP PROB: 0.2\n",
            "Iteration 0, loss = 5.1903\n",
            "Checking accuracy on validation set\n",
            "Got 2 / 3183 correct (0.06)\n",
            "\n",
            "Iteration 0, loss = 5.1651\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n",
            "Iteration 0, loss = 5.1744\n",
            "Checking accuracy on validation set\n",
            "Got 0 / 3183 correct (0.00)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_accuracy_part34(loader_test, best_model, \"test\")"
      ],
      "metadata": {
        "id": "QxX0IHt7nKBC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}