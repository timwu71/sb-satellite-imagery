{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e360e538",
   "metadata": {},
   "source": [
    "# Preprocessing Data for EC2 Instance\n",
    "\n",
    "This code is used to preprocess the data on the EC2 Instance. You should only have to run it **ONCE**, the cleaned data should be saved to this folder on the instance: [TODO: insert folder].\n",
    "\n",
    "Let me know if you have any questions! - R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "introductory-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: python-magic in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.4.25)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (1.8.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from torch) (1.19.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-magic\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d428d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import magic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abf5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dhs_final_labels.csv file in 231nproj\n",
    "df = pd.read_csv('../../../../231nproj/dhs_final_labels.csv')\n",
    "df['survey'] = df['DHSID_EA'].str[:10]\n",
    "df['cc'] = df['DHSID_EA'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vertical-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../../231nproj/data/'\n",
    "df['path'] = data_dir + df['survey'] + '/' + df['DHSID_EA'] + '.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "close-semester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../231nproj/data/AL-2008-5#/AL-2008-5#-00000001.npz\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 117644 entries, AL-2008-5#-00000001 to ZW-2015-7#-00000400\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   DHSID_EA          117644 non-null  object \n",
      " 1   cname             117644 non-null  object \n",
      " 2   year              117644 non-null  int64  \n",
      " 3   lat               117644 non-null  float64\n",
      " 4   lon               117644 non-null  float64\n",
      " 5   n_asset           86936 non-null   float64\n",
      " 6   asset_index       86936 non-null   float64\n",
      " 7   n_water           87938 non-null   float64\n",
      " 8   water_index       87938 non-null   float64\n",
      " 9   n_sanitation      89271 non-null   float64\n",
      " 10  sanitation_index  89271 non-null   float64\n",
      " 11  under5_mort       105582 non-null  float64\n",
      " 12  n_under5_mort     105582 non-null  float64\n",
      " 13  women_edu         117062 non-null  float64\n",
      " 14  women_bmi         94866 non-null   float64\n",
      " 15  n_women_edu       117062 non-null  float64\n",
      " 16  n_women_bmi       94866 non-null   float64\n",
      " 17  cluster_id        117644 non-null  int64  \n",
      " 18  adm1fips          45916 non-null   object \n",
      " 19  adm1dhs           117644 non-null  int64  \n",
      " 20  urban             117644 non-null  object \n",
      " 21  survey            117644 non-null  object \n",
      " 22  cc                117644 non-null  object \n",
      " 23  path              117644 non-null  object \n",
      "dtypes: float64(14), int64(3), object(7)\n",
      "memory usage: 22.4+ MB\n"
     ]
    }
   ],
   "source": [
    "path_years = df[['DHSID_EA', 'path', 'year']].apply(tuple, axis=1)\n",
    "df.set_index('DHSID_EA', verify_integrity=True, inplace=True, drop=False) #had to add drop=False to keep column from disappearing  -- R\n",
    "print(df['path'].iloc[0])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vertical-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_X(paths):  # -> (N, C, H, W) model input X\n",
    "  '''\n",
    "    Args\n",
    "    - paths: array (N, 1)\n",
    "      - path: str, path to npz file containing single entry 'x'\n",
    "        representing a (C, H, W) image\n",
    "\n",
    "    Returns: X, input matrix (N, C, H, W)\n",
    "    '''\n",
    "  N = len(paths)  # should be 117644\n",
    "  print(N)\n",
    "  C, H, W = 8, 255, 255\n",
    "  \n",
    "  imgs = []\n",
    "  for n in range(N):\n",
    "    npz_path = paths[n][0]\n",
    "    imgs.append(np.load(npz_path)['x'])  # shape (C, H, W)\n",
    "    if n % 2000  == 0:\n",
    "        print('On example', n)\n",
    "  \n",
    "  return np.stack(imgs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immune-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"n_under5_mort\"\n",
    "\n",
    "SPLITS = {\n",
    "    'train': [\n",
    "        'AL', 'BD', 'CD', 'CM', 'GH', 'GU', 'HN', 'IA', 'ID', 'JO', 'KE', 'KM',\n",
    "        'LB', 'LS', 'MA', 'MB', 'MD', 'MM', 'MW', 'MZ', 'NG', 'NI', 'PE', 'PH',\n",
    "        'SN', 'TG', 'TJ', 'UG', 'ZM', 'ZW'],\n",
    "    'val': [\n",
    "        'BF', 'BJ', 'BO', 'CO', 'DR', 'GA', 'GN', 'GY', 'HT', 'NM', 'SL', 'TD',\n",
    "        'TZ'],\n",
    "    'test': [\n",
    "        'AM', 'AO', 'BU', 'CI', 'EG', 'ET', 'KH', 'KY', 'ML', 'NP', 'PK', 'RW',\n",
    "        'SZ']\n",
    "}\n",
    "\n",
    "SPLITS['trainval'] = SPLITS['train'] + SPLITS['val']\n",
    "\n",
    "#partial splits\n",
    "\n",
    "SPLITS['train_partial'] = SPLITS['train'][:5]\n",
    "SPLITS['val_partial'] = SPLITS['train'][:2]\n",
    "SPLITS['test_partial'] = SPLITS['train'][:2]\n",
    "SPLITS['trainval_partial'] = SPLITS['train_partial'] + SPLITS['val_partial']\n",
    "\n",
    "\n",
    "def get_data_split(label, split):\n",
    "    train_dhsids = df.index[df['cc'].isin(SPLITS[split]) & df[label].notna()]\n",
    "    \n",
    "    train_X_paths = df.loc[train_dhsids, 'path'].values.reshape(-1, 1)\n",
    "    train_X = paths_to_X(train_X_paths)\n",
    "    train_Y = df.loc[train_dhsids, label].values\n",
    "    \n",
    "    # knn.fit(train_X, train_Y)\n",
    "    # preds = knn.predict(test_X)\n",
    "    return train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "selected-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7377\n",
      "On example 0\n",
      "On example 2000\n",
      "On example 4000\n",
      "On example 6000\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.3 GiB for an array with shape (7377, 8, 255, 255) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4789e2e4534b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_partial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_X: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_Y: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving data in folder'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data_clean/train_partial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data_clean/train_partial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f6f804de8187>\u001b[0m in \u001b[0;36mget_data_split\u001b[0;34m(label, split)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_X_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dhsids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_to_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dhsids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa4f95b82ec4>\u001b[0m in \u001b[0;36mpaths_to_X\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'On example'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mexpanded_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 14.3 GiB for an array with shape (7377, 8, 255, 255) and data type float32"
     ]
    }
   ],
   "source": [
    "train_X, train_Y = get_data_split(label, 'train_partial')\n",
    "print(\"train_X: \", train_X.shape)\n",
    "print(\"train_Y: \", train_Y.shape)\n",
    "print('Saving data in folder' + str(data_dir) + '/data_clean/train_partial')\n",
    "np.savez_compressed(str(data_dir) + 'data_clean/train_partial', train_X=train_X, train_Y=train_Y)\n",
    "\n",
    "val_X, val_Y = get_data_split(label, 'val_partial')\n",
    "print(\"val_X: \", val_X.shape)\n",
    "print(\"val_Y: \", val_Y.shape)\n",
    "print('Saving data in folder' + str(data_dir) + '/data_clean/val_partial')\n",
    "np.savez_compressed(str(data_dir) + 'data_clean/val_partial', val_X=val_X, val_Y=val_Y)\n",
    "\n",
    "test_X, test_Y = get_data_split(label, 'test_partial')\n",
    "print(\"test_X: \", test_X.shape)\n",
    "print(\"test_Y: \", test_Y.shape)\n",
    "print('Saving data in folder' + str(data_dir) + '/data_clean/test_partial')\n",
    "np.savez_compressed(str(data_dir) + 'data_clean/test_partial', test_X=test_X, test_Y=test_Y)\n",
    "\n",
    "\n",
    "# train_X, train_Y = get_data_split(label, 'train')\n",
    "# print(\"train_X: \", train_X.shape)\n",
    "# print(\"train_Y: \", train_Y.shape)\n",
    "# print('Saving data in folder' + str(data_dir) + '/data_clean/train')\n",
    "# np.savez_compressed(str(data_dir) + 'data_clean/train', train_X=train_X, train_Y=train_Y)\n",
    "\n",
    "# val_X, val_Y = get_data_split(label, 'val')\n",
    "# print(\"val_X: \", val_X.shape)\n",
    "# print(\"val_Y: \", val_Y.shape)\n",
    "# print('Saving data in folder' + str(data_dir) + '/data_clean/val')\n",
    "# np.savez_compressed(str(data_dir) + 'data_clean/val', val_X=val_X, val_Y=val_Y)\n",
    "\n",
    "# test_X, test_Y = get_data_split(label, 'test')\n",
    "# print(\"test_X: \", test_X.shape)\n",
    "# print(\"test_Y: \", test_Y.shape)\n",
    "# print('Saving data in folder' + str(data_dir) + '/data_clean/test')\n",
    "# np.savez_compressed(str(data_dir) + 'data_clean/test', test_X=test_X, test_Y=test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
